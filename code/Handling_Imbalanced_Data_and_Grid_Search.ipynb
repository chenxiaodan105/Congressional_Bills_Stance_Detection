{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = ['xiaodan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "#### 0. Data Wrangling\n",
    "* 0.1 functions for text preprocessing\n",
    "* 0.2 functions for models\n",
    "\n",
    "#### 1. Handling Imbalance Data \n",
    "* 1.1 balanced ensemble method (balanced random forest)\n",
    "* 2.2 weighted ensemble method (weighted random forest)\n",
    "\n",
    "#### 2. Grid Search\n",
    "* 2.1 grid search for text preprocessing (bow & tfidf)\n",
    "* 2.2 grid search for machine learning models\n",
    "* 2.3 grid search for imbalance data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 functions for text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    '''\n",
    "    get data\n",
    "    :return: data and its labels\n",
    "    '''\n",
    "    data = pd.read_csv(path,index_col=0)\n",
    "    return data\n",
    "\n",
    "\n",
    "def split_data(corpus, labels, test_data_proportion=0.3):\n",
    "    '''\n",
    "    :param corpus: data\n",
    "    :param labels: labels\n",
    "    :param test_data_proportion:proportion \n",
    "    '''\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(corpus, labels,\n",
    "                                                        test_size=test_data_proportion, \n",
    "                                                        random_state=42)\n",
    "    return train_X, test_X, train_Y, test_Y\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop = list(set(stopwords.words('english')))\n",
    "    tokens = tokenize_text(text)\n",
    "    filtered_tokens = [token for token in tokens if token not in stop]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    filtered_tokens = filter(None, [pattern.sub('', token) for token in tokens])\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "def text_preprocessing(corpus):\n",
    "    normalized_corpus = []\n",
    "    for text in corpus:\n",
    "        text = remove_special_characters(text)\n",
    "        text = remove_stopwords(text)\n",
    "        normalized_corpus.append(text)\n",
    "    return normalized_corpus\n",
    "\n",
    "\n",
    "def bow_model(corpus, ngram_range=(1, 1),min_df=0.1,max_df=0.9,max_features=5000):\n",
    "    vectorizer = CountVectorizer(min_df=min_df,\n",
    "                                 max_df=max_df,\n",
    "                                 stop_words='english',\n",
    "                                 ngram_range=ngram_range,\n",
    "                                 max_features = max_features)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features\n",
    "\n",
    "\n",
    "def tfidf_transformer(bow_matrix):\n",
    "    transformer = TfidfTransformer(norm='l2',\n",
    "                                   smooth_idf=True,\n",
    "                                   use_idf=True)\n",
    "    tfidf_matrix = transformer.fit_transform(bow_matrix)\n",
    "    return transformer, tfidf_matrix\n",
    "\n",
    "\n",
    "def tfidf_model(corpus, ngram_range=(1, 1),min_df=0.1,max_df=0.9,max_features=5000):\n",
    "    vectorizer = TfidfVectorizer(min_df=min_df,\n",
    "                                 max_df=max_df,\n",
    "                                 stop_words='english',\n",
    "                                 ngram_range=ngram_range,\n",
    "                                 max_features = max_features)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 functions for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_evaluate_model(classifier,\n",
    "                                 train_features, train_labels,\n",
    "                                 test_features, test_labels):\n",
    "          \n",
    "    # build model\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predict using model\n",
    "    predictions = classifier.predict(test_features)\n",
    "    # evaluate model prediction performance\n",
    "    print(get_metrics(true_labels=test_labels,predicted_labels=predictions))\n",
    "    \n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    return metrics.classification_report(true_labels,predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 get data and the result for the random forest model without dealing with imbalance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('/Users/xiaodanchen/Desktop/capstone/capstone_submit/data/cleaned_data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all '-1' class with '0'\n",
    "data2 = data.copy()\n",
    "data2['tagged'].replace({-1:0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>text</th>\n",
       "      <th>volume_no</th>\n",
       "      <th>issue_no</th>\n",
       "      <th>page_range</th>\n",
       "      <th>person_id</th>\n",
       "      <th>full_name</th>\n",
       "      <th>party</th>\n",
       "      <th>chamber</th>\n",
       "      <th>title</th>\n",
       "      <th>tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mr. GRAYSON . Mr. Speaker, these statements an...</td>\n",
       "      <td>159</td>\n",
       "      <td>42</td>\n",
       "      <td>E357-E358</td>\n",
       "      <td>29284</td>\n",
       "      <td>Alan-nan-Grayson</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>Catching Up to 1968 Act of 2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ms. GABBARD . Mr. Speaker, I rise today in str...</td>\n",
       "      <td>159</td>\n",
       "      <td>42</td>\n",
       "      <td>E362</td>\n",
       "      <td>46246</td>\n",
       "      <td>Tulsi-nan-Gabbard</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>Helping Heroes Fly Act</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Mr. FALEOMAVAEGA . Mr. Speaker, I want to shar...</td>\n",
       "      <td>159</td>\n",
       "      <td>42</td>\n",
       "      <td>E363-E364</td>\n",
       "      <td>19</td>\n",
       "      <td>Eni-F.H.-Faleomavaega</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>Non-Disparagement of Native American Persons o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>Mr. COHEN . Mr. Speaker, I rise today to share...</td>\n",
       "      <td>159</td>\n",
       "      <td>39</td>\n",
       "      <td>H1559</td>\n",
       "      <td>1762</td>\n",
       "      <td>Steve-nan-Cohen</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>Northern Route Approval Act</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Ms. JACKSON LEE . Mr. Speaker, in a few weeks,...</td>\n",
       "      <td>159</td>\n",
       "      <td>42</td>\n",
       "      <td>H1725</td>\n",
       "      <td>475</td>\n",
       "      <td>Sheila-nan-Jackson Lee</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>Child Gun Safety and Gun Access Prevention Act</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support                                               text  volume_no  \\\n",
       "0        1  Mr. GRAYSON . Mr. Speaker, these statements an...        159   \n",
       "1        1  Ms. GABBARD . Mr. Speaker, I rise today in str...        159   \n",
       "2        1  Mr. FALEOMAVAEGA . Mr. Speaker, I want to shar...        159   \n",
       "3       -1  Mr. COHEN . Mr. Speaker, I rise today to share...        159   \n",
       "4        1  Ms. JACKSON LEE . Mr. Speaker, in a few weeks,...        159   \n",
       "\n",
       "  issue_no page_range  person_id               full_name party chamber  \\\n",
       "0       42  E357-E358      29284        Alan-nan-Grayson     D       H   \n",
       "1       42       E362      46246       Tulsi-nan-Gabbard     D       H   \n",
       "2       42  E363-E364         19   Eni-F.H.-Faleomavaega     D       H   \n",
       "3       39      H1559       1762         Steve-nan-Cohen     D       H   \n",
       "4       42      H1725        475  Sheila-nan-Jackson Lee     D       H   \n",
       "\n",
       "                                               title  tagged  \n",
       "0                    Catching Up to 1968 Act of 2013       1  \n",
       "1                             Helping Heroes Fly Act       1  \n",
       "2  Non-Disparagement of Native American Persons o...       1  \n",
       "3                        Northern Route Approval Act       1  \n",
       "4     Child Gun Safety and Gun Access Prevention Act       1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data.info()\n",
    "# check if the data is imbalanced\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "data2.groupby('tagged').text.count().plot.bar(ylim=0)\n",
    "plt.title('histogram of stances')\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('vote')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data2['text'].values, data2['tagged'].values\n",
    "train_corpus, test_corpus, train_labels, test_labels = split_data(X,y,test_data_proportion=0.3)\n",
    " # normalization\n",
    "norm_train_corpus = text_preprocessing(train_corpus)\n",
    "norm_test_corpus = text_preprocessing(test_corpus)\n",
    "\n",
    "# bag of words\n",
    "bow_vectorizer, bow_train_features = bow_model(norm_train_corpus)\n",
    "bow_test_features = bow_vectorizer.transform(norm_test_corpus)\n",
    "\n",
    "# tfidf \n",
    "tfidf_vectorizer, tfidf_train_features = tfidf_model(norm_train_corpus)\n",
    "tfidf_test_features = tfidf_vectorizer.transform(norm_test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model before handling imbalance data (not recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression classifier using tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85     13589\n",
      "           1       0.12      0.77      0.21       640\n",
      "\n",
      "   micro avg       0.74      0.74      0.74     14229\n",
      "   macro avg       0.55      0.76      0.53     14229\n",
      "weighted avg       0.95      0.74      0.82     14229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(class_weight='balanced')\n",
    "# logistic regression classifier using tfidf\n",
    "print(\"logistic regression classifier using tfidf\")\n",
    "lr_tfidf_predictions = train_predict_evaluate_model(classifier=lr,\n",
    "                                                    train_features=tfidf_train_features,\n",
    "                                                    train_labels=train_labels,\n",
    "                                                    test_features=tfidf_test_features,\n",
    "                                                    test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random forest model before handling imbalance data (not recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest classifier using tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96     13589\n",
      "           1       0.19      0.15      0.16       640\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     14229\n",
      "   macro avg       0.57      0.56      0.56     14229\n",
      "weighted avg       0.93      0.93      0.93     14229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100,class_weight='balanced')\n",
    "# random forest classifier using tfidf\n",
    "print(\"random forest classifier using tfidf\")\n",
    "rfc_tfidf_predictions = train_predict_evaluate_model(classifier=rfc,\n",
    "                                                     train_features=tfidf_train_features,\n",
    "                                                     train_labels=train_labels,\n",
    "                                                     test_features=tfidf_test_features,\n",
    "                                                     test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**finding:**  the difference between the f1 score for each category is so large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Handling Imbalance Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 balanced ensemble method (balanced random forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* draw a bootstrap sample from the minority class and draw a bootstrap sample form the majority class with the same size of the minority sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* induce a classification tree to maximize size without pruning. the tree is induced with CART algorithm with the modification of only searching through a set of m randomly selected variables instead of searching through all variables to find the optimal split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* repeat 2 steps above, aggregate the predictions of the emsemble above and get the final prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* reference: https://imbalanced-learn.org/en/stable/generated/imblearn.ensemble.BalancedRandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-9c1f7518c75c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBalancedRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBalancedRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "brf = BalancedRandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced random forest classifier using tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.82      0.71       133\n",
      "           1       0.95      0.87      0.91       491\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       624\n",
      "   macro avg       0.79      0.84      0.81       624\n",
      "weighted avg       0.88      0.86      0.86       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# balanced random forest classifier using tfidf\n",
    "print(\"balanced random forest classifier using tfidf\")\n",
    "rfc_tfidf_predictions = train_predict_evaluate_model(classifier=brf,\n",
    "                                                     train_features=tfidf_train_features,\n",
    "                                                     train_labels=train_labels,\n",
    "                                                     test_features=tfidf_test_features,\n",
    "                                                     test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**finding:** metrics are all improved significantly with balanced random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 weighted ensemble method (weighted random forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* place a penalty on misclassifying the minority class. we assign a weight to each class, for the minority class we give a larger weight (i.e. higher classification cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The class weights are incorporated into the RF algorithm in two places. In the tree induction procedure, class weights are used to weight the Gini criterion for finding splits. In the terminal nodes of each tree, class weights are again taken into consideration. The class prediction of each terminal node is determined by “weighted majority vote”; i.e., the weighted vote of a class is the weight for that class times the number of cases for that class at the terminal node. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The final class prediction for RF is then determined by aggregatting the weighted vote from each individual tree, where the weights are average weights in the terminal nodes. Class weights are an essential tuning parameter to achieve desired performance. The out-of-bag estimate of the accuracy from RF can be used to select weights. This method, Weighted Random Forest (WRF), is incorporated in the present version of the software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The \"balanced\" mode uses the values of y to automatically adjust\n",
    "#weights inversely proportional to class frequencies in the input data as \n",
    "#``n_samples / (n_classes * np.bincount(y))``\n",
    "#ref: \n",
    "wrf_rf = RandomForestClassifier(n_estimators=100,class_weight='balanced')\n",
    "wrf_brf = BalancedRandomForestClassifier(n_estimators=100,class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted random forest classifier using tfidf\n",
    "print(\"weighted random forest classifier using tfidf\")\n",
    "rfc_tfidf_predictions = train_predict_evaluate_model(classifier=wrf_rf,\n",
    "                                                     train_features=tfidf_train_features,\n",
    "                                                     train_labels=train_labels,\n",
    "                                                     test_features=tfidf_test_features,\n",
    "                                                     test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted balanced random forest classifier using tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.80      0.62       133\n",
      "           1       0.94      0.79      0.86       491\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       624\n",
      "   macro avg       0.72      0.80      0.74       624\n",
      "weighted avg       0.85      0.79      0.81       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# weighted balanced random forest classifier using tfidf\n",
    "print(\"weighted balanced random forest classifier using tfidf\")\n",
    "rfc_tfidf_predictions = train_predict_evaluate_model(classifier=wrf_brf,\n",
    "                                                     train_features=tfidf_train_features,\n",
    "                                                     train_labels=train_labels,\n",
    "                                                     test_features=tfidf_test_features,\n",
    "                                                     test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**findings:** the performance of the balanced ensemble method is better than the weighted method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 grid search for text preprocessing (bow & tfidf) and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__class_weight': (None, 'balanced'),\n",
      " 'tfidf__max_df': (0.8, 0.9),\n",
      " 'tfidf__min_df': (0.1, 0.2),\n",
      " 'tfidf__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 219.328s\n",
      "\n",
      "Best score: 0.858\n",
      "Best parameters set:\n",
      "\tclf__class_weight: None\n",
      "\ttfidf__max_df: 0.9\n",
      "\ttfidf__min_df: 0.1\n",
      "\ttfidf__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#print(__doc__)\n",
    "# Display progress logs on stdout\n",
    "#logging.basicConfig(level=logging.INFO,format='%(asctime)s %(levelname)s %(message)s')\n",
    "# Define a pipeline combining a text feature extractor with a simple classifier\n",
    "rfc = RandomForestClassifier()\n",
    "brf = BalancedRandomForestClassifier()\n",
    "pipeline = Pipeline([('tfidf', TfidfVectorizer()),('clf', brf)])\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {'tfidf__max_df': (0.7,0.8, 0.9),\n",
    "              'tfidf__min_df': (0.1, 0.2,0.3),\n",
    "              #'tfidf__max_features': (5000, 10000),\n",
    "              'tfidf__ngram_range': ((1,1),(1, 2)),  # unigrams or bigrams\n",
    "              'clf__n_estimators': (100,150),\n",
    "              'clf__max_depth': (10,30,50),\n",
    "              'clf__class_weight': (None, 'balanced')}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected block\n",
    "    # find the best parameters for both the feature extraction and the classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(norm_train_corpus, train_labels)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
